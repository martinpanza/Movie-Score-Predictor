{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3: Clasificación (Parte 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Evaluar un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos las librerías y los datos necesarios para este laboratorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ejecutar este bloque para cargar las librerías\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el Iris Dataset, que viene en `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Data:\\n', array([[ 123, 1916],\n",
      "       [ 151, 1925],\n",
      "       [ 145, 1927],\n",
      "       [ 110, 1929],\n",
      "       [ 100, 1929]], dtype=int64))\n",
      "('Target:\\n', array(['8.0', '8.3', '8.3', '8.0', '6.3'], \n",
      "      dtype='|S6'), array(['6.8', '6.7', '7.8', '7.7', '7.8'], \n",
      "      dtype='|S6'), array(['4.6', '3.5', '8.5', '3.4', '4.9'], \n",
      "      dtype='|S6'))\n"
     ]
    }
   ],
   "source": [
    "## ejecutar este bloque\n",
    "\n",
    "# comma delimited is the default\n",
    "data = pd.read_csv(\"Data.csv\", header = 0)\n",
    "target = pd.read_csv(\"Target.csv\", header = 0)\n",
    "\n",
    "# put the original column names in a python list\n",
    "original_headers_data = list(data.columns.values)\n",
    "\n",
    "\n",
    "# create a numpy array with the numeric values for input into scikit-learn\n",
    "data = data.as_matrix()\n",
    "target = np.ravel(target.as_matrix())\n",
    "target = np.asarray(target, dtype=\"|S6\")\n",
    "\n",
    "print(\"Data:\\n\", data[:5])\n",
    "print(\"Target:\\n\", target[:5], target[95:100], target[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los datos de entrenamiento son tuplas de 4 dimensiones, mientras que la clase de cada dato corresponde a un valor 0, 1 o 2. En el campo `DESCR` de la variable `iris` están los detalles del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ejecutar este bloque para ver el contenido de DESCR\n",
    "# print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ejecutamos el bloque anterior, podemos ver que el dataset consiste en 150 observaciones y 3 clases, donde cada observación corresponde a 4 características de una flor, sus dimensiones, mientras que la clase corresponde a la especie de la flor (iris-setosa, iris-virginica e iris-versicolor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para evaluar un clasificador, típicamente tenemos 3 formas:\n",
    "\n",
    "1. Entrenamos con los *datos de entrenamiento*, y evaluamos el clasificador en los *datos de entrenamiento*.\n",
    "2. Antes de entrenar, separamos nuestros datos en *datos de entrenamiento* y *datos de prueba*. Entrenamos sobre el primer conjunto y evaluamos el rendimiento del clasificador sobre el segundo.\n",
    "3. Usamos el paso (2), pero separando los datos muchas veces y entrenando y evaluando sobre un conjunto distinto cada vez. Esta forma es llamada *cross-validation*.\n",
    "\n",
    "Llamaremos indistintamente a los *datos de entrenamiento* como el *Training set* y a los *datos de prueba* como el *Test set*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1\n",
    "\n",
    "Vamos a usar el clasificador K-NN (K-Nearest Neighbors), usando distintas formas de evaluación, y vamos a compararlas mediante el Accuracy o Exactitud.\n",
    "\n",
    "### (1) Training Set\n",
    "\n",
    "A continuación vamos a entrenar un clasificador K-NN con todos los datos que tenemos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ejecutar este código\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `knn.predict(...)` determina la clase de los datos entregados como parámetro. \n",
    "\n",
    "Por ejemplo si ejecutáramos ```knn.predict([[1.0, 2.0, 3.0, 1.0]])```, le estamos pasando al clasificador un dato con valores `[1.0, 2.0, 3.0, 1.0]`. Al ejecutar `predict`, éste nos retornará un arreglo con el valor `0`, indicando que esos datos fueron clasificados como la clase `0`.\n",
    "\n",
    "**Modifique el código a continuación para determinar el Accuracy del clasificador probando sobre todos los datos de entrenamiento.**\n",
    "\n",
    "### Respuesta (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.6       0.33      1.00      0.50         1\n",
      "        1.7       0.17      1.00      0.29         1\n",
      "        1.9       0.14      0.50      0.22         2\n",
      "        2.0       0.15      1.00      0.27         2\n",
      "        2.1       0.16      1.00      0.27         3\n",
      "        2.2       0.14      1.00      0.25         1\n",
      "        2.3       0.50      0.33      0.40         3\n",
      "        2.4       0.17      1.00      0.29         2\n",
      "        2.5       0.14      1.00      0.25         1\n",
      "        2.6       0.17      1.00      0.29         1\n",
      "        2.7       0.25      0.60      0.35         5\n",
      "        2.8       0.14      0.80      0.24         5\n",
      "        2.9       0.11      0.33      0.17         3\n",
      "        3.0       0.19      1.00      0.32         3\n",
      "        3.1       0.18      0.75      0.29         4\n",
      "        3.2       1.00      1.00      1.00         1\n",
      "        3.3       0.18      0.64      0.29        11\n",
      "        3.4       0.21      0.50      0.30         6\n",
      "        3.5       0.16      0.40      0.23        10\n",
      "        3.6       0.21      0.58      0.30        12\n",
      "        3.7       0.21      0.83      0.33         6\n",
      "        3.8       0.18      0.69      0.29        13\n",
      "        3.9       0.26      0.82      0.39        11\n",
      "        4.0       0.11      0.33      0.17        12\n",
      "        4.1       0.17      0.70      0.28        20\n",
      "        4.2       0.17      0.53      0.25        17\n",
      "        4.3       0.19      0.61      0.29        23\n",
      "        4.4       0.14      0.35      0.20        23\n",
      "        4.5       0.18      0.58      0.28        24\n",
      "        4.6       0.19      0.41      0.26        37\n",
      "        4.7       0.13      0.42      0.20        24\n",
      "        4.8       0.19      0.44      0.27        39\n",
      "        4.9       0.20      0.51      0.28        47\n",
      "        5.0       0.22      0.43      0.29        35\n",
      "        5.1       0.22      0.40      0.29        63\n",
      "        5.2       0.21      0.48      0.29        63\n",
      "        5.3       0.20      0.31      0.24        80\n",
      "        5.4       0.17      0.36      0.23        90\n",
      "        5.5       0.24      0.39      0.29        85\n",
      "        5.6       0.18      0.34      0.23       106\n",
      "        5.7       0.20      0.41      0.27       105\n",
      "        5.8       0.22      0.30      0.25       111\n",
      "        5.9       0.24      0.34      0.28       136\n",
      "        6.0       0.21      0.26      0.23       112\n",
      "        6.1       0.24      0.26      0.25       163\n",
      "        6.2       0.26      0.24      0.25       161\n",
      "        6.3       0.26      0.23      0.25       160\n",
      "        6.4       0.29      0.27      0.28       171\n",
      "        6.5       0.26      0.17      0.20       177\n",
      "        6.6       0.29      0.18      0.23       184\n",
      "        6.7       0.31      0.18      0.23       201\n",
      "        6.8       0.32      0.16      0.21       167\n",
      "        6.9       0.29      0.14      0.19       156\n",
      "        7.0       0.31      0.13      0.18       163\n",
      "        7.1       0.34      0.15      0.21       163\n",
      "        7.2       0.36      0.17      0.23       168\n",
      "        7.3       0.39      0.16      0.23       166\n",
      "        7.4       0.39      0.12      0.18       128\n",
      "        7.5       0.32      0.08      0.12       117\n",
      "        7.6       0.35      0.16      0.22       114\n",
      "        7.7       0.27      0.03      0.05       102\n",
      "        7.8       0.37      0.08      0.13        91\n",
      "        7.9       0.50      0.07      0.12        61\n",
      "        8.0       0.43      0.14      0.22        70\n",
      "        8.1       0.58      0.12      0.20        59\n",
      "        8.2       0.25      0.03      0.06        31\n",
      "        8.3       0.75      0.09      0.16        34\n",
      "        8.4       0.33      0.04      0.08        23\n",
      "        8.5       0.33      0.10      0.15        21\n",
      "        8.6       0.00      0.00      0.00        11\n",
      "        8.7       0.00      0.00      0.00         9\n",
      "        8.8       0.00      0.00      0.00         5\n",
      "        8.9       1.00      0.20      0.33         5\n",
      "        9.0       0.00      0.00      0.00         2\n",
      "        9.2       0.00      0.00      0.00         1\n",
      "        9.3       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.29      0.23      0.22      4444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### COMPLETAR ACÁ\n",
    "\n",
    "target_pred = knn.predict(data)\n",
    "accuracy_score(target, target_pred)\n",
    "\n",
    "print(classification_report(target, target_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Test Set\n",
    "\n",
    "La función `cross_validation.train_test_split(X, y, test_size=p, random_state=N)` divide los arreglos `X` e `y` en dos arreglos, haciendo un muestreo de sus datos de forma consistente para generar un dataset de entrenamiento y otro de pruebas; `test_size` indica la fracción del total para asignar el tamaño del conjunto de pruebas. El parámetro `random_state` sirve para tener resultados consistentes tras cada ejecución.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ejecutar este código\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.33, random_state=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escriba el código necesario para determinar el Accuracy del clasificador, esta vez entrenando sobre el Training set y probando sobre el Test set.**\n",
    "\n",
    "### Respuesta (2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        17\n",
      "          1       1.00      0.93      0.96        14\n",
      "          2       0.95      1.00      0.97        19\n",
      "\n",
      "avg / total       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### COMPLETAR ACÁ\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Cross-validation\n",
    "\n",
    "Con cross-validation, el conjunto de entrenamiento se divide en $k$ conjuntos disjuntos; se entrena sobre los datos correspondientes a $k-1$ de éstos, y se evalúa sobre el conjunto restante. Esto se repite $k$ veces, evaluando siempre sobre un conjunto distinto. Teniendo en cuenta el parámetro $k$, a éste método se le llama $k$-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96666667,  1.        ,  0.93333333,  0.96666667,  1.        ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ejecutar este código\n",
    "\n",
    "cross_validation.cross_val_score(knn, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior va a realizar 5-fold cross-validation usando el clasificador K-NN sobre los datos. Después se puede tomar el promedio y el intervalo de confianza de los resultados para tener otra medida de rendimiendo del clasificador. \n",
    "\n",
    "(Por defecto, `cross_val_score` llama al método `score` del clasificador, el cual en este caso es el Accuracy. Es posible cambiar la métrica en los parámetros de `cross_val_score`.)\n",
    "\n",
    "**¿Por qué es necesario usar cross-validation? O bien, ¿en qué casos cree que es mejor que sólo separar los datos en Training Set y Test Set?**\n",
    "\n",
    "Para ilustrar el problema, pruebe cambiando el valor del parámetro `random_state` en el siguiente código y determine el Accuracy del clasificador resultante con cada valor de `random_state` escogido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        16\n",
      "          1       1.00      0.90      0.95        20\n",
      "          2       0.88      1.00      0.93        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        50\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        18\n",
      "          1       0.94      0.94      0.94        18\n",
      "          2       0.93      0.93      0.93        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## modificar acá\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.33, random_state=75)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.33, random_state=715)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta (3):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario usar Cross-Validation debido a que los resultados de accuracy para cada predicción pueden variar dependiendo de la random seed que se use. En este sentido, es más confiable realizar la predicción varias veces con distinta random seed y utilizar un promedio o determinar un error asociado que nos puede informar de situaciones de overfitting por ejemplo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2\n",
    "\n",
    "Imagine que tenemos un dataset sobre el cual queremos entrenar un buen clasificador. Para esto, usamos cross-validation como forma de evaluación. Usamos cientos, miles de distintos modelos sobre nuestros datos, hasta encontrar el modelo que obtenga los mejores resultados sobre el dataset. ¿Qué se puede esperar en términos de rendimiento al aplicar el modelo final sobre datos no vistos anteriormente? ¿Cómo asocia esta situación al Overfitting? Proponga una mejor forma de estimar el rendimiento del modelo final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, si se usan demasiados modelos sobre los datos, es decir, se hace cross validation demasiadas veces, además de afectar el rendimiento global del clasificador ya que se está ejecutando muchas veces, se pierde la credibilidad de éste debido a que se produce overfitting puesto que puede que el modelo se esté ajustando demasiado a un caso en específico. Idealmente, hay que evitar el Underfitting y el Overfitting, buscando un punto intermedio entre estos. Es decir, no hay que hacer ni muy pocas iteraciones ni demasiadas. Una buena forma de estimar un buen rendimiento, es verificar el porcentaje de error en el Test Set al clasficar. Si luego de n iteraciones del cross validation este porcentaje empieza a aumentar, entonces ya se hicieron suficientes iteraciones y se tiene un modelo decente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Métricas de evaluación\n",
    "\n",
    "## Pregunta 3\n",
    "\n",
    "**(a)** Dada la siguiente matriz de confusión, determine **Accuracy**, **Precision**, **Recall**, $F_{1}$ **-score** por cada clase, y cantidad de **Falsos Positivos** y **Falsos Negativos**. Puede escribir un código que entregue la respuesta, o sólo escribir cómo llegó al resultado, además de la respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| A  | B  | C  | ← clasificado como / clase real ↓ |\n",
    "|:----:|:----:|:----:|--------------------:|\n",
    "| 21 | 2  | 4  |              **A** |\n",
    "| 0  | 7  | 2  |              **B** |\n",
    "| 2  | 15 | 27 |              **C** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase A:\n",
      "Accuracy = 0.9\n",
      "Precision = 0.913043478261\n",
      "Recall = 0.777777777778\n",
      "F1-Score = 0.84\n",
      "\n",
      "Clase B:\n",
      "Accuracy = 0.7625\n",
      "Precision = 0.291666666667\n",
      "Recall = 0.777777777778\n",
      "F1-Score = 0.424242424242\n",
      "\n",
      "Clase C:\n",
      "Accuracy = 0.7125\n",
      "Precision = 0.818181818182\n",
      "Recall = 0.613636363636\n",
      "F1-Score = 0.701298701299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def precision(TP, FP):\n",
    "    return TP/(TP+FP)\n",
    "    \n",
    "def recall(TP, FN):\n",
    "    return TP/(TP+FN)\n",
    "    \n",
    "def F1(TP, FP, FN):\n",
    "    return 2*(precision(TP, FP))*(recall(TP, FN))/((precision(TP, FP))+(recall(TP, FN)))\n",
    "    \n",
    "def accuracy(corr, tot):\n",
    "    return corr/tot\n",
    "\n",
    "print(\"Clase A:\" + \"\\n\" + \"Accuracy = \" + str(accuracy(72., 80.)) + \"\\n\" +\n",
    "     \"Precision = \" + str(precision(21., 2.)) + \"\\n\" + \n",
    "     \"Recall = \" + str(recall(21., 6.)) + \"\\n\" +\n",
    "     \"F1-Score = \" + str(F1(21., 2., 6.)) + \"\\n\")\n",
    "\n",
    "print(\"Clase B:\" + \"\\n\" + \"Accuracy = \" + str(accuracy(61., 80.)) + \"\\n\" +\n",
    "     \"Precision = \" + str(precision(7., 17.)) + \"\\n\" + \n",
    "     \"Recall = \" + str(recall(7., 2.)) + \"\\n\" +\n",
    "     \"F1-Score = \" + str(F1(7., 17., 2.)) + \"\\n\")\n",
    "\n",
    "print(\"Clase C:\" + \"\\n\" + \"Accuracy = \" + str(accuracy(57., 80.)) + \"\\n\" +\n",
    "     \"Precision = \" + str(precision(27., 6.)) + \"\\n\" + \n",
    "     \"Recall = \" + str(recall(27., 17.)) + \"\\n\" +\n",
    "     \"F1-Score = \" + str(F1(27., 6., 17.)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Dé un ejemplo de escenario de clasificación en el cual sea más conveniente apuntar por un mayor **Recall** que por **Precision**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Un ejemplo claro consiste en tener un clasificador que diga positivo cuando una persona tiene cáncer y negativo cuando no tiene. Tomando esto en cuenta, un Falso Positivo es decirle a una persona que tiene cáncer cuando en realidad esa persona no tiene; mientras que un Falso Negativo es decirle a una persona que no tiene cáncer cuando en realidad sí lo tiene, lo que claramente es peor que el primer caso. Entonces, en este caso es conveniente tener un mayor Recall ya que significaría que hubo menos Falsos Negativos (no le dije a tantas personas que no tenían cáncer cuando sí tenían), en cambio no es \"tan malo\" tener más Falsos Positivos ya que no es tan terrible decirle a una persona que sí tenía cuando en realidad no lo tiene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Bonus) Parte 3: Selección de modelo\n",
    "\n",
    "Un uso práctico de cross-validation es el elegir el clasificador más conveniente para los datos.\n",
    "\n",
    "Vamos a usar el dataset de cáncer de mamas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "breast = load_breast_cancer()\n",
    "\n",
    "X = breast.data\n",
    "y = breast.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "        \n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "        \n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ======= ========\n",
      "                                           Min     Max\n",
      "    ===================================== ======= ========\n",
      "    radius (mean):                         6.981   28.11\n",
      "    texture (mean):                        9.71    39.28\n",
      "    perimeter (mean):                      43.79   188.5\n",
      "    area (mean):                           143.5   2501.0\n",
      "    smoothness (mean):                     0.053   0.163\n",
      "    compactness (mean):                    0.019   0.345\n",
      "    concavity (mean):                      0.0     0.427\n",
      "    concave points (mean):                 0.0     0.201\n",
      "    symmetry (mean):                       0.106   0.304\n",
      "    fractal dimension (mean):              0.05    0.097\n",
      "    radius (standard error):               0.112   2.873\n",
      "    texture (standard error):              0.36    4.885\n",
      "    perimeter (standard error):            0.757   21.98\n",
      "    area (standard error):                 6.802   542.2\n",
      "    smoothness (standard error):           0.002   0.031\n",
      "    compactness (standard error):          0.002   0.135\n",
      "    concavity (standard error):            0.0     0.396\n",
      "    concave points (standard error):       0.0     0.053\n",
      "    symmetry (standard error):             0.008   0.079\n",
      "    fractal dimension (standard error):    0.001   0.03\n",
      "    radius (worst):                        7.93    36.04\n",
      "    texture (worst):                       12.02   49.54\n",
      "    perimeter (worst):                     50.41   251.2\n",
      "    area (worst):                          185.2   4254.0\n",
      "    smoothness (worst):                    0.071   0.223\n",
      "    compactness (worst):                   0.027   1.058\n",
      "    concavity (worst):                     0.0     1.252\n",
      "    concave points (worst):                0.0     0.291\n",
      "    symmetry (worst):                      0.156   0.664\n",
      "    fractal dimension (worst):             0.055   0.208\n",
      "    ===================================== ======= ========\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "A few of the images can be found at\n",
      "http://www.cs.wisc.edu/~street/images/\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870, \n",
      "     San Jose, CA, 1993. \n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(breast.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinaremos el valor de $K$ en el clasificador K-NN que entregue mejor Precision.\n",
    "\n",
    "Para esto, use el promedio del Precision en cross-validation con 10 folds para cada valor de $K$ y grafique los resultados en `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### COMPLETAR ACÁ\n",
    "\n",
    "cv_scores = list()\n",
    "k_range = range(1, 50)\n",
    "\n",
    "for k in k_range:\n",
    "    folds = list()\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.33, random_state=8)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    folds = cross_validation.cross_val_score(knn, X, y, cv=10, scoring='precision')\n",
    "    cv_scores.append(float(sum(folds))/len(folds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xb2b7ac8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAF5CAYAAABEPIrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niZmZmVXKfwG6AMYVFnDRVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaf98a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ejecutar este código al terminar el bloque anterior\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(k_range, cv_scores)\n",
    "plt.ylabel(\"precision\")\n",
    "plt.xlabel(\"K-nearest neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
