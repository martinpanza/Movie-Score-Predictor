{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer Intento de clasificador\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el titulo lo dice, primer intento de clasificador usando como referencia el laboratorio x .\n",
    "Se considera para este caso el archivo movies_final_imdb el cual contiene:\n",
    "    \n",
    "    movieId+nota_imbd_aprox+duracion+categoria+actores+directores\n",
    "    \n",
    "    \n",
    "Nota : Falta agregar los directores y quizas las fechas para ve como cambia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Librerias Basicas:\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Metricas y Estadisticas:\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "# Clasificadores : Tree, SVM, RandomForest, Regression, Naive Bayes,KNN......\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"movies_final.csv\", header = 0)\n",
    "score = pd.read_csv(\"imdb.csv\", header = 0)\n",
    "\n",
    "movies_header = list(movies.columns.values)\n",
    "movies = movies.as_matrix()\n",
    "\n",
    "score = np.ravel(score.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores y Validación.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Esta nueva seccion calcula el promedio del accuracy de varios tipos de clasificadores y despues corre un test estadistico para determinar si existe una diferencia significativa entre el clasificador que se está probando y los otros.\n",
    "\n",
    "~Algo asi como un cross validation.\n",
    "\n",
    "\n",
    "Definimos las funciones del clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variar el num_test modifica la probabilidad de estar mas cerca del promedio al hacer un t-test. \n",
    "#Creo que con 35 es suficiente para ese tipo de distribuciones.\n",
    "\n",
    "def run_classifier(clf, X, y, num_tests=10):\n",
    "    scores = []\n",
    "    reports = []\n",
    "    \n",
    "    for i in range(num_tests):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "        clf.fit(X_train, y_train)\n",
    "        scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificadores usados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c0 = (\"Base\", DummyClassifier(strategy='stratified'))\n",
    "c1 = (\"SVM\", SVC(kernel='linear'))\n",
    "c2 = (\"DT\", DecisionTreeClassifier())\n",
    "c3 = (\"NB\", GaussianNB())\n",
    "c4 = (\"KNN\", KNeighborsClassifier(n_neighbors=5))\n",
    "c5 = (\"RandomForest\", RandomForestClassifier(n_estimators=10))\n",
    "c6 = (\"LogisticRegression\",LogisticRegression())\n",
    "\n",
    "classifiers = [c0, c1, c2, c3, c4,c5,c6]\n",
    "result_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos las pruebas para cada test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Funcion Pesada, correr solo una vez. \n",
    "\n",
    "for name, clf in classifiers:\n",
    "    accuracys = run_classifier(clf ,movies , score)\n",
    "    result_list.append((name, accuracys))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Impresion de los resultados\n",
    "\n",
    "print(\"+ indica diferencia significativa\\n\")\n",
    "\n",
    "for name1, results1 in result_list:\n",
    "    print(\"Comparando %s - Accuracy: %.2f\" % (name1, results1.mean()))\n",
    "    for name2, results2 in result_list:\n",
    "        if name1 == name2:\n",
    "            continue\n",
    "\n",
    "        _, p_value, __ = ttest_ind(results1, results2)\n",
    "        \n",
    "        if p_value <= 0.05:\n",
    "            sig = \"+\"\n",
    "        else:\n",
    "            sig = \"\"\n",
    "        print(\"%s:\\t%.2f %s\" % (name2, results2.mean(), sig))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones de algunas peliculas\n",
    "\n",
    "Usando la siguiente funcion, se puede imprimir mas facilmente los resultados y luego calcular algunas metricas importantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for clf_name, clf in classifiers:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(movies, score, test_size =  0.30)\n",
    "    clf.fit(X_train, y_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_movies = [(\"Toy Story\", movies[0], score[0]),(\"Avatar\", movies[3111], score[3111]),\n",
    "                 (\"Titanic\",movies[458],score[458]),(\"Transformers\",movies[4057],score[4057]),\n",
    "                 (\"Never Say Never\",movies[4189],score[4189])]\n",
    "predicted_scores = []\n",
    "\n",
    "# Toma un vector de tuplas nombre,clasificador y otro de nombre_pelicula,atributos,score_original y\n",
    "# trata de predecir el score de esto para luego compararlos.\n",
    "def predict_scores(clf, sample_movies):    \n",
    "    for clf_name , clf in clf:\n",
    "        for sample_name, sample_data, sample_score in sample_movies:\n",
    "            predicted_scores.append((clf_name, sample_name,clf.predict(sample_data),sample_score))\n",
    "    return predicted_scores\n",
    "\n",
    "res = predict_scores(classifiers, sample_movies)\n",
    "\n",
    "def predict_scores_toString(predicted_scores):\n",
    "    string = \"Clf\\t\\t\\tNombrePelicula\\t\\t\\tNotaPredicha\\t\\tNotaReal\\n\"\n",
    "    for item in predicted_scores:\n",
    "        for elements in item:\n",
    "            string = str(string) + str(elements) + \"\\t\\t\\t\"\n",
    "        string = str(string) + \"\\n\"\n",
    "    return string\n",
    "        \n",
    "#Muchos Warnings :(        \n",
    "\n",
    "res2 = predict_scores_toString(res)\n",
    "print res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busqueda del mejor train test\n",
    "\n",
    "A traves de graficos, trataremos de buscar el mejor test-train para cada clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_intervals(number):\n",
    "    intervals = []\n",
    "    for i in range(number):\n",
    "        intervals.append(float(i)/number)\n",
    "    \n",
    "    return intervals[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Funcion que determina la mejor proporcion del conjunto de entrenamiento \n",
    "# y retorna la lista mas el mejor clasificador generado.\n",
    "def best_test_size(clf, X, y, intervals, test_iterations):\n",
    "    scores_final = []\n",
    "    scores = []\n",
    "    best_clf = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for i in intervals:\n",
    "        for j in range(test_iterations):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = i)\n",
    "            clf.fit(X_train, y_train)\n",
    "            clf_score = clf.score(X_test, y_test)\n",
    "            scores.append(clf_score)\n",
    "            if (best_accuracy < clf_score):\n",
    "                best_accuracy = clf_score\n",
    "                best_clf = clf\n",
    "            \n",
    "            \n",
    "        \n",
    "        #Agrego el promedio de los resultados.\n",
    "        scores_final.append(sum(scores) / float(len(scores)))\n",
    "        \n",
    "        #Vacio las listas.\n",
    "        scores = []\n",
    "            \n",
    "    print scores_final  \n",
    "    return (np.array(scores_final),best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "intervalos1 = 10\n",
    "\n",
    "test_size_results = []\n",
    "intervals = create_intervals(intervalos1)\n",
    "\n",
    "for clf_name, clf in classifiers:\n",
    "    print \"CLF Actual: \" + clf_name\n",
    "    test_results = best_test_size (clf, movies, score, 10,2) \n",
    "    #print test_results\n",
    "    plt.plot(create_intervals(10),test_results)\n",
    "    plt.ylabel('Accuracy de '+ clf_name)\n",
    "    plt.show()\n",
    "    test_size_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Conclusion. Aparentemente, SVM con Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejor Parametro KNN (numero de vecinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_parameter_KNN(X, y,parameters,tsize):\n",
    "    scores = []\n",
    "    param = []\n",
    "    \n",
    "    for i in range(parameters):\n",
    "        param.append(i+1)\n",
    "        for j in range(tsize):\n",
    "            results = []\n",
    "            clf = KNeighborsClassifier(n_neighbors=i+1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
    "            clf.fit(X_train, y_train)\n",
    "            results.append(clf.score(X_test, y_test))\n",
    "        \n",
    "        scores.append(sum(results) / float(len(results)))\n",
    "        results = []\n",
    "    #Imprimo el grafico!\n",
    "                      \n",
    "    print 'Accuracy de KNN con ' + str(parameters) + ' parametros y ' + str(tsize) + ' iteraciones x parametro.'\n",
    "    print param\n",
    "    plt.plot(param,scores)\n",
    "    plt.ylabel('Accuracy de KNN') \n",
    "    plt.xlabel('Numero de Parametros')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "best_parameter_KNN(movies,score,30,15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mejor Parametro RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_parameter_RF(X, y,parameters,tsize):\n",
    "    scores = []\n",
    "    param = []\n",
    "    \n",
    "    for i in range(parameters):\n",
    "        param.append(i+1)\n",
    "        for j in range(tsize):\n",
    "            results = []\n",
    "            clf = RandomForestClassifier(n_estimators=i+1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
    "            clf.fit(X_train, y_train)\n",
    "            results.append(clf.score(X_test, y_test))\n",
    "        \n",
    "        scores.append(sum(results) / float(len(results)))\n",
    "        results = []\n",
    "    #Imprimo el grafico!\n",
    "                      \n",
    "    print 'Accuracy de KNN con ' + str(parameters) + ' parametros y ' + str(tsize) + ' iteraciones x parametro.'\n",
    "    print param\n",
    "    plt.plot(param,scores)\n",
    "    plt.ylabel('Accuracy de KNN') \n",
    "    plt.xlabel('Numero de Parametros')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "best_parameter_RF(movies,score,30,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n",
    "\n",
    "Para llegar a este test se hizo lo siguiente :\n",
    "\n",
    "    1.Se determino en el test1 cuales eran los clasificadores que daban mejores resultados.\n",
    "\n",
    "    2.Se determino (solo para 0.30 el tamaño del dataset) cuales eran los mejores parametros para random forest tree y KNN.\n",
    "\n",
    "Aun falta :\n",
    "\n",
    "Determinar los mejores resultados (usando algun algoritmo greedy) cual es el optimo de parametros para knn y random forest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test 2 . Parametros :\n",
    "\n",
    "#Intervalos por probar\n",
    "intervals2 = [0.1,0.2,0.3,0.4,0.5]\n",
    "#Numero de iteraciones probadas.\n",
    "iteraciones2 = 1\n",
    "\n",
    "\n",
    "test_size_results = []\n",
    "\n",
    "\n",
    "c00 = (\"Base\", DummyClassifier(strategy='stratified'))\n",
    "c11 = (\"SVM\", SVC(kernel='linear'))\n",
    "c22 = (\"KNN\", KNeighborsClassifier(n_neighbors=30))\n",
    "c33 = (\"LogisticRegression\",LogisticRegression())\n",
    "\n",
    "classifiers2 = [c00, c11, c22, c33]\n",
    "best_classifiers = []\n",
    "\n",
    "for clf_name, clf in classifiers2:\n",
    "    test_results2 = best_test_size (clf, movies, score, intervals2,iteraciones2) \n",
    "    best_classifiers.append(test_results2[1])\n",
    "    \n",
    "    #print test_results\n",
    "    plt.plot(intervals2,test_results2[0])\n",
    "    plt.ylabel('Accuracy de '+ clf_name)\n",
    "    plt.show()\n",
    "    test_size_results2 = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imprimo los classification report de los mejores clasificadores que se obtuvieron. \n",
    "clf_names = [\"Dummy:\\n\", \"SVM:\\n\", \"KNN:\\n\", \"Logistic Regression:\\n\"]\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "i = 0\n",
    "for clf in best_classifiers:\n",
    "    print clf_names[i]\n",
    "    score_pred = OneVsRestClassifier(clf.predict(movies))\n",
    "    print(classification_report(score,score_pred))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas :\n",
    "    Clasificadores Pipeline : Peliculas (mala,buena) -> Peliculas (malas, medias, buenas) -> Peliculas(muy malas,malas,medias,buenas,muy buenas).\n",
    "\n",
    "Que porcentaje de peliculas no tiene suficientes metadatos. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File imdb_mayor3.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-987bb66518df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cargamos el archivo imbd_mayor3 que tiene 2 clases : 1 si la nota es mayor que 3 y 0 si no.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores_greater3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imdb_mayor3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscores_greater3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_greater3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pablo/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pablo/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pablo/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pablo/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pablo/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File imdb_mayor3.csv does not exist"
     ]
    }
   ],
   "source": [
    "# Cargamos el archivo imbd_mayor3 que tiene 2 clases : 1 si la nota es mayor que 3 y 0 si no.\n",
    "\n",
    "scores_greater3 = pd.read_csv(\"imdb_mayor3.csv\", header = 0)\n",
    "scores_greater3 = np.ravel(scores_greater3.as_matrix())\n",
    "\n",
    "greater3_clf = LogisticRegression()\n",
    "scores = cross_validation.cross_val_score( greater3_clf,movies , scores_greater3, cv=15)\n",
    "print scores\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(movies, scores_greater3, test_size = 0.30)\n",
    "greater3_clf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(scores_greater3,greater3_clf.predict(movies)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbol de clasificadores \n",
    "    \n",
    "    Tratamos de asignarle sentido a lo que estamos clasificando a través de varios clasificadores ordenados en un arbol.\n",
    "   \n",
    "Usaremos Regresion Logistica.   \n",
    "   \n",
    "Aun resta por ver Clasificador OneVSAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Funciones Genericas\n",
    "\n",
    "#Carga un archivo con scores\n",
    "def load_archive(name):\n",
    "    archive = pd.read_csv(name, header = 0)\n",
    "    archive = np.ravel(archive.as_matrix())\n",
    "    return archive\n",
    "\n",
    "#Carga un archivo con meta-datos\n",
    "def load_text_archive(name):\n",
    "    movies = pd.read_csv(name, header = 0)\n",
    "    movies_header = list(movies.columns.values)\n",
    "    movies = movies.as_matrix()\n",
    "    return movies\n",
    "\n",
    "#Entrena a los clasificadores usando los dataset correspondientes.\n",
    "def train_trees(classifiersTree, movies, score_datasets):\n",
    "    trained_classifiersTree = []\n",
    "    for i in range(len(classifiersTree)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(movies_datasets[i], scores_datasets[i], test_size = 0.5)\n",
    "        classifiersTree[i].fit(X_train, y_train)\n",
    "        trained_classifiersTree.append(classifiersTree[i])\n",
    "    return trained_classifiersTree\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbol 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Definiciones Previas\n",
    "\n",
    "#Clasificadores\n",
    "clf_cmp4 = LogisticRegression() # 0 si es menor que 4, 1 de lo contrario.\n",
    "clf_1to4 = LogisticRegression() # Clasifica en un rango de notas de 1 a 4.\n",
    "clf_cmp7 = LogisticRegression() # 0 si es menor que 7, 1 de lo contrario\n",
    "clf_5to7 = LogisticRegression() # Clasifica de 4 a 7. \n",
    "clf_8to10 = LogisticRegression() # Clasifica de 8 a 10.\n",
    "\n",
    "#Archivos y Arrays.\n",
    "\n",
    "movies_0to4 = load_text_archive(\"movies_0to4.csv\")\n",
    "movies_5to7 = load_text_archive(\"movies_5to7.csv\")\n",
    "movies_8to10 = load_text_archive(\"movies_8to10.csv\")\n",
    "\n",
    "scores_cmp4 = load_archive(\"scores_cmp4.csv\")\n",
    "scores_0to4 = load_archive(\"scores_0to4.csv\")\n",
    "scores_cmp7 = load_archive(\"scores_cmp7.csv\")\n",
    "scores_5to7 = load_archive(\"scores_5to7.csv\")\n",
    "scores_8to10 =load_archive(\"scores_8to10.csv\")\n",
    "\n",
    "#Arrays Listos\n",
    "classifiersTree = [clf_cmp4,clf_1to4,clf_cmp7,clf_5to7,clf_8to10 ] \n",
    "movies_datasets = [movies, movies_0to4, movies,movies_5to7,movies_8to10]\n",
    "scores_datasets = [scores_cmp4, scores_0to4, scores_cmp7 ,scores_5to7,scores_8to10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Funciones.\n",
    "#(\"Toy Story\", movies[0], score[0])\n",
    "#Entrenamos el arbol.!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definimos el arbol con la siguiente funcion:\n",
    "def predict_with_clfTree(classifiersTree,value_to_predict):\n",
    "    \n",
    "    #Clasifico si la nota es mayor o menor que 4.\n",
    "    if (classifiersTree[0].predict(value_to_predict)):\n",
    "        #Clasifico si la nota es mayor o menor que 7\n",
    "        if (classifiersTree[2].predict(value_to_predict)):\n",
    "            return classifiersTree[4].predict(value_to_predict)\n",
    "            #Si es menor clasifico \n",
    "        else:\n",
    "            return classifiersTree[3].predict(value_to_predict)\n",
    "        \n",
    "    #Si es menor que 4: \n",
    "    else:\n",
    "        return classifiersTree[1].predict(value_to_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A ver que tal funciona!\n",
    "\n",
    "#Creamos el arbol con los clasificadores.\n",
    "\n",
    "classifiersTree = train_trees(classifiersTree,movies_datasets,scores_datasets)\n",
    "\n",
    "scores_predicted = []\n",
    "for i in range(len(movies)):\n",
    "    scores_predicted.append(predict_with_clfTree(classifiersTree,movies[i].reshape(1, -1))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       0.43      0.38      0.40        16\n",
      "          3       0.42      0.12      0.19        40\n",
      "          4       0.44      0.33      0.38       171\n",
      "          5       0.59      0.34      0.43       478\n",
      "          6       0.57      0.74      0.64      1487\n",
      "          7       0.69      0.61      0.65      1497\n",
      "          8       0.69      0.65      0.67       728\n",
      "          9       0.24      0.60      0.34        35\n",
      "\n",
      "avg / total       0.62      0.62      0.61      4452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imprimimos el reporte\n",
    "print classification_report(score,scores_predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbol 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_0to5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-9f408899c4e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mclassifiersTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclf_cmp5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_equal5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_1to4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_cmp8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_6to7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_8to10\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmovies_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovies_0to5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovies_0to4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovies_cmp8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovies_6to7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmovies_8to10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mscores_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscores_cmp5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores_0to5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_0to4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_cmp8\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0mscores_6to7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores_8to10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_0to5' is not defined"
     ]
    }
   ],
   "source": [
    "#Definiciones Previas\n",
    "\n",
    "#Clasificadores\n",
    "clf_cmp5 = LogisticRegression() # 0 si es menor que 5, 1 de lo contrario.\n",
    "clf_equal5 = LogisticRegression() # 0 si es menor que 5, 1 si es 5.\n",
    "clf_1to4 = LogisticRegression() # Clasifica en un rango de notas de 1 a 4.\n",
    "clf_cmp8 = LogisticRegression() # 0 si es menor que 8, 1 de lo contrario\n",
    "clf_6to7 = LogisticRegression() # Clasifica de 6 a 7. \n",
    "clf_8to10 = LogisticRegression() # Clasifica de 8 a 10.\n",
    "\n",
    "#Archivos y Arrays.\n",
    "\n",
    "movies_0to4 = load_text_archive(\"movies_0to4.csv\")\n",
    "movies_0to5 = load_text_archive(\"movies_0to5.csv\")\n",
    "movies_6to7 = load_text_archive(\"movies_6to7.csv\")\n",
    "movies_8to10 = load_text_archive(\"movies_8to10.csv\")\n",
    "movies_cmp8 = load_text_archive(\"movies_cmp8.csv\")\n",
    "\n",
    "scores_cmp5 = load_archive(\"scores_cmp5.csv\")\n",
    "scores_0to4 = load_archive(\"scores_0to4.csv\")\n",
    "scores_cmp8 = load_archive(\"scores_cmp8.csv\")\n",
    "scores_6to7 = load_archive(\"scores_6to7.csv\")\n",
    "scores_8to10 =load_archive(\"scores_8to10.csv\")\n",
    "\n",
    "#Arrays Listos\n",
    "classifiersTree = [clf_cmp5,clf_equal5,clf_1to4,clf_cmp8,clf_6to7,clf_8to10 ] \n",
    "movies_datasets = [movies,movies_0to5, movies_0to4,movies_cmp8,movies_6to7,movies_8to10]\n",
    "scores_datasets = [scores_cmp5,scores_0to5, scores_0to4, scores_cmp8  ,scores_6to7,scores_8to10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predice y evalua.\n",
    "def predict_with_clfTree2(classifiersTree,value_to_predict):\n",
    "    \n",
    "    #Clasifico si la nota es mayor o menor que 5.\n",
    "    if (classifiersTree[0].predict(value_to_predict)):\n",
    "        #Clasifico si la nota es mayor o menor que 8:\n",
    "        if (classifiersTree[3].predict(value_to_predict)):\n",
    "            #Si es mayor, clasifico entre 8-9\n",
    "            return classifiersTree[5].predict(value_to_predict)\n",
    "            \n",
    "        else:\n",
    "            #Si es menor clasifico en el rango 6-8\n",
    "            return classifiersTree[4].predict(value_to_predict)\n",
    "        \n",
    "    #Si es menor que 5: \n",
    "    else:\n",
    "        if(classifiersTree[1].predict(value_to_predict)):\n",
    "            return 5\n",
    "        else:\n",
    "            return classifiersTree[2].predict(value_to_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_predicted2 = []\n",
    "for i in range(len(movies)):\n",
    "    scores_predicted2.append(predict_with_clfTree(classifiersTree,movies[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print classification_report(score,scores_predicted2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
